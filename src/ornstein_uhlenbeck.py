from typing import List

from matplotlib import pyplot as plt
import numpy
import pyro
import pyro.distributions as dist
import pyro.infer as infer
import pyro.optim as optim
import torch
from pyro import poutine
from pyro.infer.autoguide import AutoDelta

import datagen


class OrnsteinUhlenbeckProcess2D(torch.nn.Module):
    """
    A stationary zero drift term 2D Ornstein-Uhlenbeck process model.
    """

    def __init__(
        self,
        dt: float,
        wishart_df: float = 10,
        sigma_lkj_concentration: float = 2,
        sigma_sd_param: List[float] = (2.5, 2.5),
        device: str = "cpu",
    ) -> None:
        """
        Args:
            dt (float): The time step for the process.
            wishart_df (float, optional): Degrees of freedom for the Wishart prior on the drift matrix. Defaults to 10.
            sigma_lkj_concentration (float, optional): Concentration parameter for the LKJ prior on the sigma correlation matrix. Defaults to 2.
            sigma_sd_param (List[float], optional): Scale parameters for the Half-Cauchy prior on sigma standard deviations. Defaults to (2.5, 2.5).
            device (str, optional): The device (CPU or GPU) on which to run the computations. Defaults to "cpu".
        """
        super(OrnsteinUhlenbeckProcess2D, self).__init__()

        self._dt = dt
        self._wishart_df = wishart_df
        self._sigma_lkj_concentration = sigma_lkj_concentration
        self._sigma_sd_param = sigma_sd_param

        self._device = device
        self.to(device)

    def model(self, data: List[torch.Tensor]) -> None:
        """
        Defines the model for the 2D Ornstein-Uhlenbeck process using the Euler-Maruyama method.

        The model assumes that N observations were generated by the same stationary Ornstein-Uhlenbeck process with no drift, and that the observations are 
        conditionally independent given the latent process. 

        Stationarity is encoded in the distribution of the drift matrix. Sampling it from the Wishart distribution ensures 
        that it will always be positive definite, and consequently the process will be stationary. Zero drift term is encoded in the model by using a 
        constant zero vector for the drift term. The covariance matrix of the process is created from the sampled correlation matrix and standard
        deviation, sampled from an LKJ distribution and a Half Cauchy distribution, respectively. 

        It only works with SVI, MCMC in Pyro will fail because of the positivity constraints in the Wishart distribution 
        (see [here](https://forum.pyro.ai/t/mcmc-for-mixture-of-gaussians/5144)). 
    
        Args:
            data (List[torch.Tensor]): A list of torch.Tensor objects, each representing data for a single relaization of the process.
            Each tensor should be two-dimensional, where:
            - The first dimension represents the number of data points observed for each simulation.
            - The second dimension represents the two dimensions of the Ornstein-Uhlenbeck process state space.

        Returns:
            None
        """
        # Sample the drift matrix from a Wishart distribution
        beta_drift_matrix = pyro.sample(
            name="beta_drift_matrix",
            fn=dist.Wishart(df=self._wishart_df, covariance_matrix=torch.eye(2))
        ).to(self._device)

        # Sample the sigma correlation matrix from an LKJ distribution
        # This is the correlation matrix of the diffusion matrix
        # We'll sample the standard deviations from a Half-Cauchy distribution
        # and then use the LKJ distribution to parameterize the correlation matrix
        # using the sampled standard deviations.
        sigma_corr_matrix = pyro.sample(
            name="sigma_corr",
            fn=dist.LKJ(dim=2, concentration=self._sigma_lkj_concentration),
        ).to(self._device)

        sigma_sd = pyro.sample(
            name="sigma_sd",
            fn=dist.HalfCauchy(scale=torch.Tensor(self._sigma_sd_param)).to_event(1),
        ).to(self._device)

        sigma_sd_diag = torch.diag(sigma_sd)

        sigma_cov_matrix = torch.mm(
            torch.mm(sigma_sd_diag, sigma_corr_matrix), sigma_sd_diag
        )

        # The drift term is hardcoded to zero
        # If we want to model non-zero drift, we need to convert it into a pyro.param or pyro.sample call
        drift_term = torch.zeros(2, device=self._device)

        for idx in pyro.plate("realizations", size=len(data)):
            num_data_points_for_fixation = data[idx].shape[0]
            x = torch.zeros(2, device=self._device)  # Initial value at zero

            for t in pyro.markov(range(num_data_points_for_fixation), history=1):
                diff = drift_term - x
                x_mean = x + torch.matmul(beta_drift_matrix, diff) * self._dt
                x_covariance = sigma_cov_matrix * self._dt

                # Sample from the multivariate Gaussian conditioned on the observed data
                x = pyro.sample(
                    name=f"x_{idx}_{t}",
                    fn=dist.MultivariateNormal(
                        loc=x_mean, covariance_matrix=x_covariance
                    ),
                    obs=data[idx][t, ...],
                )


def infer_ornstein_uhlenbeck_process_vi(
    data: List[torch.Tensor],
    ou_model: OrnsteinUhlenbeckProcess2D,
    adam_parameters: dict,
    num_steps: int,
):
    """Infers parameters of an Ornstein-Uhlenbeck process using variational inference.

    This function performs variational inference on the parameters of a 2D
    Ornstein-Uhlenbeck process model using Stochastic Variational Inference (SVI).
    It optimizes the model parameters to fit the provided data using an AutoDelta guide.

    Args:
        data (List[torch.Tensor]): A list of 2D tensors, each representing a
            realization of the Ornstein-Uhlenbeck process with the same parameters.
        ou_model (OrnsteinUhlenbeckProcess2D): An instance of the
            OrnsteinUhlenbeckProcess2D class representing the model.
        adam_parameters (dict): A dictionary of parameters for the Adam optimizer.
        num_steps (int): The maximum number of optimization steps to perform.

    Returns:
        tuple: A tuple containing:
            - loss_trace (list): A list of ELBO loss values at each optimization step.
            - beta_drift_matrix (torch.Tensor): The inferred drift matrix.
            - sigma_cov_matrix (torch.Tensor): The inferred covariance matrix.

    Raises:
        ValueError: If the input data is empty or not in the correct format.
        RuntimeError: If the optimization fails to converge within the specified
            number of steps.

    Note:
        This function uses early stopping based on the convergence of the loss
        function. It will stop if the difference between the maximum and minimum
        loss over the last 10 iterations is less than 2.
    """

    # Define guide, ie. the variational distribution q(x)
    # Here we chose a Dirac Delta guide, it just finds MAP estimates of 'exposed' variables.
    guide = AutoDelta(
        poutine.block(
            ou_model.model, expose=["beta_drift_matrix", "sigma_corr", "sigma_sd"]
        )
    )

    # Define optimizer, loss and the SVI object
    optimizer = optim.Adam(adam_parameters)
    elbo = infer.Trace_ELBO(max_plate_nesting=1)
    svi = infer.SVI(ou_model.model, guide, optimizer, elbo)

    # Inference loop
    # We're using early stopping, so we don't need to run for num_steps, it's just an upper limit.
    loss_trace = list()
    for step in range(num_steps):
        loss = svi.step(data)
        loss_trace.append(loss)
        print("Step: {: >5d}, loss: \t{}".format(step, loss))
        if step > 30 and max(loss_trace[-10:]) - min(loss_trace[-10:]) < 2:
            print("Convergence achieved with", step, "iterations")
            break

    # If we reach the upper limit of iterations, we should notify the user.
    if step == num_steps - 1:
        print("WARNING: uncertain convergence!")

    # Extract the parameters we optimized for
    beta_drift_matrix = pyro.get_param_store().get_param("AutoDelta.beta_drift_matrix")
    sigma_corr = pyro.get_param_store().get_param("AutoDelta.sigma_corr")
    sigma_sd = pyro.get_param_store().get_param("AutoDelta.sigma_sd")

    # Calculate the values we want
    sigma_sd_diag = torch.diag(sigma_sd)
    sigma_cov_matrix = torch.mm(torch.mm(sigma_sd_diag, sigma_corr), sigma_sd_diag)

    return loss_trace, beta_drift_matrix, sigma_cov_matrix


def _test():
    """
    Test the Ornstein-Uhlenbeck process inference with synthetic data.
    We generate the data from a known set of parameters, and then we try to infer the parameters of the model.
    We compare the inferred parameters to the actual parameters used to generate the data to gauge the accuracy of the inference.
    """
    # Set the device
    device = "cpu"

    # Set the random seed for reproducibility
    numpy.random.seed(0)
    torch.manual_seed(0)

    # Define parameters for data generation
    fs_simultaion = 1000.0
    B_simulation = 5 * numpy.eye(2)
    Sigma_simulation = 0.5 * numpy.eye(2)
    num_simulations = 5

    # Print the actual parameters used for simulation so we can later compare them to our inference results
    print("Real B (drift matrix):")
    print(B_simulation, end="\n\n")
    print("Real Sigma (diffusion matrix):")
    print(Sigma_simulation, end="\n\n")

    # Generate the data
    data = datagen.generate_ou_2d_process(num_simulations, 500, 1/fs_simultaion, B_simulation, Sigma_simulation)

    # Change data type from numpy.ndarray to torch.Tensor, and move to appropriate device
    data = [torch.Tensor(ed).to(device) for ed in data]

    # Define parameters for the model and inference
    fs = 1000.0
    dt = 1 / fs
    adam_parameters = {"lr": 0.01, "betas": (0.9, 0.999)}
    num_steps = 500  # This is the maximum number of iterations we allow the optimizer to run

    # Define the model
    ou2d = OrnsteinUhlenbeckProcess2D(dt=dt, device=device)

    # Run inference
    loss_trace, beta_drift_matrix, sigma_cov_matrix = infer_ornstein_uhlenbeck_process_vi(
        data=data, ou_model=ou2d, adam_parameters=adam_parameters, num_steps=num_steps
    )

    # Convert to numpy array and print
    beta_drift_matrix_numpy = beta_drift_matrix.detach().cpu().numpy()
    sigma_cov_numpy = sigma_cov_matrix.detach().cpu().numpy()

    print()
    print(f"Beta Drift Matrix: \n{beta_drift_matrix_numpy}")
    print(f"Sigma Covariance Matrix: \n{sigma_cov_numpy}")

    # Display the loss trace
    plt.plot(loss_trace)
    plt.xlabel("Step")
    plt.ylabel("Loss")
    plt.title("Loss Trace")
    plt.show()


if __name__ == "__main__":
    assert pyro.__version__ == "1.9.1"

    _test()
